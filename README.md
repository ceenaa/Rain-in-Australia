# Machine Learning Project: Classification Using KNN, SVM, and Decision Tree

## Overview
This Jupyter notebook presents a comprehensive analysis and classification task using three machine learning models: K-Nearest Neighbors (KNN), Support Vector Machine (SVM), and Decision Tree. The notebook includes all necessary steps from data preparation, visualization, model fitting, hyperparameter tuning, and evaluation through classification reports.

## Introduction
In this notebook, we explore a classification problem using three popular machine learning algorithms: KNN, SVM, and Decision Tree. The aim is to compare the performance of these models and select the most suitable one for the task at hand.

## Dataset
Renamed format of this [dataset](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package)

## Data Preparation

This section details the data cleaning and preprocessing steps:
- Handling missing values
- Feature encoding (if applicable)
- Data normalization/standardization
- Splitting the data into training and testing sets

## Exploratory Data Analysis (EDA)

In this section, we provide visualizations and statistical analysis of the dataset to gain insights into the data. This includes:
- Distribution of features
- Correlation between features
- Feature importance analysis

## Modeling

### K-Nearest Neighbors (KNN)

- **Parameters**: Explanation of key parameters used (e.g., number of neighbors).
- **Results**: Summary of the model’s performance.

### Support Vector Machine (SVM)

- **Parameters**: Explanation of key parameters (e.g., kernel type).
- **Results**: Summary of the model’s performance.

### Decision Tree

- **Parameters**: Explanation of key parameters (e.g., max depth).
- **Results**: Summary of the model’s performance.

## Hyperparameter Tuning

A detailed explanation of the hyperparameter tuning process, including:
- The method used (e.g., GridSearchCV, RandomizedSearchCV)
- Best parameters found and how they improved model performance

## Evaluation

Here, we evaluate the performance of the models using metrics such as:
- Accuracy
- Precision
- Recall
- F1-Score
- Confusion Matrix

This section also includes a comparison of the models based on the evaluation metrics.
